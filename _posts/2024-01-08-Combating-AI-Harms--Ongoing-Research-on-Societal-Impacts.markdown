---
layout: post
title: "Combating AI Harms: Ongoing Research on Societal Impacts"
date:   2024-01-08 11:50:43 +0000
categories: News
excerpt_image: https://independentleft.ie/wp-content/uploads/2021/04/AI-and-society-1024x591.png
---
### Understanding the Rise of AI-Generated Content
With advances in techniques like GPT-3 and GANs, artificial intelligence is increasingly capable of generating realistic text, images, videos and other multimedia content. While this brings opportunities, it also raises concerns about potential misuse and unintended harms. Fabricated media spread on social platforms or in the news could mislead the public and undermine trust if viewers cannot distinguish AI outputs from real information. More research is needed to understand how the general public perceives and responds specifically to AI-generated misinformation compared to human-created deceptions.

![](https://independentleft.ie/wp-content/uploads/2021/04/AI-and-society-1024x591.png)
### Evidence that Fabricated Media Can Influence Beliefs
Existing research provides some clues about societal risks. Studies have found that fabricated images, videos and text articles can influence people's beliefs and opinions if they cannot discern that the content is not authentic. Fabricated political propaganda spread on social media, for example, has been used in attempts to sway election outcomes in some countries. While the specific impacts of AI-generated deceptions are still unclear, this suggests widespread or manipulative use could undermine democratic processes and decision making to some degree if left unaddressed.
### Open Questions around Public Perception of AI Outputs 
Many open questions remain around how the general public perceives AI-generated media and the potential for being misled. Individual understanding and reaction likely depends on factors such as media and technology literacy. Large-scale surveys could help provide insights into prevalent misconceptions and beliefs around different types of AI outputs. Analyzing social media engagement and information spread under varying visibility conditions may also offer clues about susceptibility. Continued exploration is needed to fully understand societal risks and guide responsible development.
### Case Studies Showing Fabricated Media Can Damage Trust
Trust is paramount for a well-functioning information ecosystem and democracy. When fake information spreads, it risks undermining faith in sources like news media and institutions over time. Case studies have found fabricated images and text articles used for political propaganda successfully eroded trust in some situations by calling authentic reporting into question. As AI generation techniques improve, some experts worry the possibility of rampant manipulation through fabricated videos, images and other media on a wide scale could significantly damage trust in information sources society-wide if left unchecked. More research is still needed but this represents a serious threat if not appropriately mitigated. 
### Potential Harms of Advanced Deepfakes and Manipulated Media
With generative adversarial networks (GANs) and other techniques rapidly advancing, risks are growing around misleading use cases. Deepfake videos designed to incite panic or violence through entirely fictional scenarios are a concern. Nonconsensual generation of individuals' faces onto other bodies or into fictional situations risks real privacy and identification harms. Regulating usage that violates privacy or spreads deliberate lies will become increasingly difficult as Deepfakes and other manipulated media become more advanced and realistic. Researchers aim to better understand the new types of harms emerging to help guide responsible usage and appropriate policy approaches.
### Approaches for Addressing Societal Risks from AI  
Technological strategies show promise for addressing some risks through attribution and transparency. Digital watermarking of AI-generated content could help establish clear provenance and origins. Platform and model transparency through techniques like model cards aims to expose potential biases or unknown harms. Prebunking efforts aim to inoculate the public against manipulation by proactively addressing common misconceptions. Investing in media and digital literacy also builds critical thinking skills to help citizens better identify manipulated media. A multifaceted approach including technological solutions, education and policy will likely be needed to mitigate societal threats from advanced AI systems.
### Directions for Future AI Impact Research
To keep pace with evolving risks, ongoing interdisciplinary research is imperative. Studies with larger, more diverse samples can provide more accurate understanding of societal impacts like changes to beliefs, behaviors or trust from exposure to AI misinformation at scale. Analysis of social spread under controlled conditions may offer insights into manipulation vulnerabilities. Techniques for bias detection in generated text, images or other outputs aim to ensure systems do not propagate real-world harms unintentionally. Approaches like constitutional AI target aligning advanced models with societal values like truth and fairness. Continued progress monitoring through multimodal impact research ensures AI development paths remain responsible.
### Securing Responsible AI Innovation 
As AI capabilities continue to develop rapidly, proactively addressing societal risks remains paramount. A collaborative, multidisciplinary approach involving technologists, social scientists, policymakers and others offers the best path forward. Continued impact monitoring, mitigation development through various methods, and public education will help maximize AI's benefits while avoiding unintended harms. With sustained effort, responsible innovation can help society harness new technologies safely and for the benefit of all. The alternative risks losing control of powerful systems or facing widespread distrust that sets back social progress. Open dialogue and cooperation across fields will be key to navigating this imperative challenge of our times.